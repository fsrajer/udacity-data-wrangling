{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap - Prague\n",
    "## Choose file and show summary about its tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "\n",
    "#osm_filename = \"prague_sample_k1000.osm\"\n",
    "#osm_filename = \"prague_sample_k500.osm\"\n",
    "#osm_filename = \"prague_sample_k250.osm\"\n",
    "#osm_filename = \"prague_sample_k100.osm\"\n",
    "#osm_filename = \"prague_sample_k25.osm\"\n",
    "osm_filename = \"prague_czech-republic.osm\"\n",
    "\n",
    "csv_filename_nodes = \"nodes.csv\"\n",
    "csv_filename_nodes_tags = \"nodes_tags.csv\"\n",
    "csv_filename_ways = \"ways.csv\"\n",
    "csv_filename_ways_nodes = \"ways_nodes.csv\"\n",
    "csv_filename_ways_tags = \"ways_tags.csv\"\n",
    "csv_filename_users = \"users.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-5971684b21ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mosm_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-5971684b21ec>\u001b[0m in \u001b[0;36mcount_tags\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcount_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"start\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mtags\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for _, elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "        if elem.tag not in tags:\n",
    "            tags[elem.tag] = 1\n",
    "        else:\n",
    "            tags[elem.tag] += 1\n",
    "    return tags\n",
    "\n",
    "pprint.pprint(count_tags(osm_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_colon_word = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\, \\t\\r\\n]') # we allow for a dot as opposed to the case-study code\n",
    "\n",
    "# Returns parsed type or None if not possible\n",
    "def ensure_type(str_value, expected_type):\n",
    "    \n",
    "    # avoids converting strings to strings - so it doesn't have to handle non-ascii chars\n",
    "    if expected_type == type(str()):\n",
    "        return str_value\n",
    "    \n",
    "    try:\n",
    "        return expected_type(str_value)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# My pprint class which handles utf8\n",
    "# source:\n",
    "# https://stackoverflow.com/questions/10883399/unable-to-encode-decode-pprint-output\n",
    "class PP(pprint.PrettyPrinter):\n",
    "    def format(self, object, context, maxlevels, level):\n",
    "        if isinstance(object, unicode):\n",
    "            return (object.encode('utf8'), True, False)\n",
    "        return pprint.PrettyPrinter.format(self, object, context, maxlevels, level)\n",
    "\n",
    "pp = PP()\n",
    "\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mappings for parsing .osm into python dictionary/csv\n",
    "# structure of the following variables is (original_name, type, target_name)\n",
    "\n",
    "node_fields_names = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "node_fields = zip(node_fields_names, \\\n",
    "                    map(type, [int(), float(), float(), str(), int(), int(), int(), str()]), \\\n",
    "                    node_fields_names)\n",
    "\n",
    "way_fields_names = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "way_fields = zip(way_fields_names, \\\n",
    "                    map(type, [int(), str(), int(), int(), int(), str()]),\n",
    "                    way_fields_names)\n",
    "\n",
    "tag_fields = zip(['k', 'v'], \\\n",
    "                map(type, [str(), str()]), \\\n",
    "                ['key', 'value'])\n",
    "\n",
    "way_nodes_fields = zip(['ref'], \\\n",
    "                       [type(int())], \\\n",
    "                       ['node_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All audit functions have the same return signature, i.e., (result1, result2, ..., errs), where results are what you expect or None if there was a failure. If results are None then errs is always non-empty list with info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse any element into dictionary using the given fields\n",
    "def audit_fields(elem, fields):\n",
    "    errs = []\n",
    "    parsed = {}\n",
    "    for field, field_type, dict_field in fields:\n",
    "        if field not in elem.attrib:\n",
    "            errs.append(('missing value', field))\n",
    "        else:\n",
    "            value = ensure_type(elem.get(field), field_type)\n",
    "            if not value:\n",
    "                errs.append(('wrong type', field))\n",
    "            else:\n",
    "                parsed[dict_field] = value\n",
    "    \n",
    "    if errs:\n",
    "        parsed = None\n",
    "    return parsed, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for problematic characters and \n",
    "# split key if it has structure abc:def \n",
    "#      -> set 'type' to abc and 'key' to def\n",
    "def audit_tag_key(tag):\n",
    "    key = tag['key']\n",
    "    errs = []\n",
    "    if re.search(problemchars, key):\n",
    "        tag = None\n",
    "        errs.append(('problematic characters in key', re.search(problemchars, key).group(0)))\n",
    "    elif re.match(word_colon_word, key):\n",
    "        sep = key.index(':')\n",
    "        tag['type'] = key[:sep]\n",
    "        tag['key'] = key[sep+1:]\n",
    "    return tag, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern_postcode_alternative = re.compile(r'^[0-9]{3} [0-9]{2}$')\n",
    "\n",
    "# Check bounds of the postcode.\n",
    "# Prague region included fully, Central Bohemian and Usti nad Labem regions partially\n",
    "def audit_postcode(tag):\n",
    "    errs = []\n",
    "    try:\n",
    "        if re.match(pattern_postcode_alternative, tag['value']):\n",
    "            tag['value'] = tag['value'].replace(' ', '')\n",
    "        postcode = int(tag['value'])\n",
    "        if not (10000 <= postcode <= 29599 or 40000 <= postcode <= 44199):\n",
    "            tag = None\n",
    "            errs = ['postcode outside of valid range']\n",
    "    except:\n",
    "        tag = None\n",
    "        errs = ['postcode not integer']\n",
    "    return tag, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_streetname(tag):\n",
    "    errs = []\n",
    "    tag['value'] = tag['value'].replace(u'nám.',u'náměstí')\n",
    "    return tag, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_country(tag):\n",
    "    errs = []\n",
    "    if tag['value'] != 'CZ':\n",
    "        errs = ['wrong country']\n",
    "\n",
    "    return errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_housenumber(tag):\n",
    "    tag['value'] = tag['value'].replace('ev. ','ev.')\n",
    "    return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Auxiliary definitions for checking consistency of house ids \n",
    "\n",
    "# Patterns for checking all types of house ids in the Czech system\n",
    "pattern_conscription = r'[1-9]+?[0-9]*'\n",
    "pattern_street = r'[1-9]+?[0-9]*[a-zA-Z]?'\n",
    "pattern_provisional = r'[1-9]+?[0-9]*'\n",
    "patterns_house_id = \\\n",
    "            {'conscription': re.compile(r'^' + pattern_conscription + '$'), # popisne\n",
    "            'street': re.compile(r'^' + pattern_street + '$'), # orientacni\n",
    "            'provisional': re.compile(r'^' + pattern_provisional + '$'), # evidencni\n",
    "            'house': re.compile(r'^' + \\\n",
    "                    '(ev\\.' + pattern_provisional + ')|(' + pattern_conscription + ')' \\\n",
    "                        + '(/' + pattern_street + ')?$')} # ((ev.)evidencni)|(popisne)(/orientacni)?\n",
    "\n",
    "def has_some_house_id(tags):\n",
    "    for tag in tags:\n",
    "        if tag['key'][:-6] in patterns_house_id:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_house_ids(tags):\n",
    "    house_id = {}\n",
    "    for tag in tags:\n",
    "        id_type = tag['key'][:-6]\n",
    "        \n",
    "        if id_type in patterns_house_id: \n",
    "            house_id[id_type] = tag['value']\n",
    "            \n",
    "    return house_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify that all house id tags are consistent\n",
    "def audit_house_id(tags):\n",
    "    \"\"\"\n",
    "    Verify that all house id tags are consistent and try to\n",
    "    fill in the missing ones if they can be inferred.\n",
    "    If there is some inconsistency, tags will be returned\n",
    "    in their original format and the second return value will\n",
    "    be error info.\n",
    "    \"\"\"\n",
    "\n",
    "    house_id = get_house_ids(tags)\n",
    "    errs = []\n",
    "    \n",
    "    # check that the patterns are correct\n",
    "    for id_type, id_value in house_id.items():\n",
    "        \n",
    "        match = re.match(patterns_house_id[id_type], id_value)\n",
    "        \n",
    "        # unusual format, maybe that house is a street number only\n",
    "        if id_type == 'house':\n",
    "                \n",
    "            # this handles a few cases which are in the database\n",
    "            if id_value[0] == '?':\n",
    "                id_value = id_value[1:]\n",
    "            if id_value[0] == '/':\n",
    "                id_value = id_value[1:]\n",
    "                    \n",
    "            # either nothing else is known, so test street pattern\n",
    "            # or street is known so test equality\n",
    "            if (len(house_id) == 1 and not match and re.match(patterns_house_id['street'], id_value)) \\\n",
    "                    or ('street' in house_id and house_id['street'] == id_value): \n",
    "                \n",
    "                # keep only street tag - house will be composed correctly later\n",
    "                house_id['street'] = id_value\n",
    "                del house_id['house']\n",
    "                tags = [tag for tag in tags if tag['key'] != 'housenumber']\n",
    "                match = True \n",
    "        \n",
    "        if not match:\n",
    "            errs.append((id_type + ' does not match pattern', id_value))\n",
    "    \n",
    "    if errs:\n",
    "        return tags, [('House id pattern not matching', errs, tags)]\n",
    "    \n",
    "    if 'provisional' in house_id and 'conscription' in house_id:\n",
    "        errs.append(('We cannot have both provisional and conscription', house_id))    \n",
    "    \n",
    "    # house unknown, use other fields to compose it\n",
    "    elif 'house' not in house_id:\n",
    "        housenumber = ''\n",
    "        if 'conscription' in house_id:\n",
    "            housenumber = house_id['conscription']\n",
    "        elif 'provisional' in house_id:\n",
    "            housenumber = 'ev.' + house_id['provisional']\n",
    "        \n",
    "        if 'street' in house_id:\n",
    "            housenumber = housenumber + '/' + house_id['street']\n",
    "        \n",
    "        if housenumber != '':\n",
    "            tags.append({'id': tags[0]['id'], # all tags have parent's id\n",
    "                    'key': 'housenumber',\n",
    "                    'value': housenumber,\n",
    "                    'type': 'addr'})\n",
    "    \n",
    "    # use house to check or fill in other fields \n",
    "    else:\n",
    "        is_provisional = house_id['house'][:3] == 'ev.'\n",
    "        if is_provisional:\n",
    "            house_id['house'] = house_id['house'][3:]\n",
    "            first_name = 'provisional'\n",
    "        elif house_id['house'][0] == '/':\n",
    "            first_name = ''\n",
    "        else:\n",
    "            first_name = 'conscription'\n",
    "            \n",
    "        sep = house_id['house'].find('/')\n",
    "        has_street = sep >= 0\n",
    "        \n",
    "        first = house_id['house']\n",
    "        if has_street:\n",
    "            second = first[sep+1:]\n",
    "            first = first[:sep]\n",
    "            \n",
    "        if first_name in house_id:\n",
    "            if first != house_id[first_name]:\n",
    "                errs.append(('First number is not consistent', house_id))\n",
    "        elif first != '' and first_name != '':\n",
    "            tags.append({'id': tags[0]['id'], # all tags have parent's id\n",
    "                    'key': first_name + 'number',\n",
    "                    'value': first,\n",
    "                    'type': 'addr'})\n",
    "            \n",
    "        if has_street:\n",
    "            if 'street' in house_id:\n",
    "                if second != house_id['street']:\n",
    "                    errs.append(('Street number is not consistent', house_id))\n",
    "            else:\n",
    "                tags.append({'id': tags[0]['id'], # all tags have parent's id\n",
    "                        'key': 'streetnumber',\n",
    "                        'value': second,\n",
    "                        'type': 'addr'})\n",
    "        \n",
    "    return tags, errs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_tags(elem):\n",
    "    tags = []\n",
    "    errs = []\n",
    "    for tag in elem.iter('tag'):\n",
    "        parsed, errs_curr = audit_fields(tag, tag_fields)\n",
    "        if parsed:\n",
    "            parsed['id'] = int(elem.get('id'))\n",
    "            parsed['type'] = 'regular'\n",
    "            parsed, errs_curr = audit_tag_key(parsed)\n",
    "        \n",
    "        if parsed and parsed['type'] == 'addr':\n",
    "            if parsed['key'] == 'postcode':\n",
    "                parsed, errs_curr = audit_postcode(parsed)\n",
    "            elif parsed['key'] == 'street':\n",
    "                parsed, errs_curr = audit_streetname(parsed)\n",
    "            elif parsed['key'] == 'country':\n",
    "                errs_curr = audit_country(parsed)\n",
    "            elif parsed['key'] == 'housenumber':\n",
    "                parsed = audit_housenumber(parsed)\n",
    "        \n",
    "        if errs_curr:\n",
    "            errs.append(('ignored tag', tag.attrib, errs_curr))\n",
    "        if parsed:\n",
    "            tags.append(parsed)\n",
    "    \n",
    "    if errs:\n",
    "        errs = [(errs, tags)]\n",
    "    \n",
    "    if has_some_house_id(tags):\n",
    "        tags, errs_curr = audit_house_id(tags)\n",
    "        if errs_curr:\n",
    "            errs.append(errs_curr)\n",
    "    \n",
    "    return tags, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check bounds of latitude and longitude\n",
    "def audit_location(node):\n",
    "    errs = []\n",
    "    for bound, field in zip([90., 180.], ['lat', 'lon']):\n",
    "        if not (-bound <= node[field] <= bound):\n",
    "            errs.append(('invalid value', field, node))\n",
    "            node = None\n",
    "            break\n",
    "    return node, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse node and its tags\n",
    "def audit_node(node):\n",
    "    parsed, errs = audit_fields(node, node_fields)\n",
    "            \n",
    "    if parsed:\n",
    "        parsed, errs_loc = audit_location(parsed)\n",
    "        tags, errs_tags = audit_tags(node)\n",
    "        errs = errs_loc + errs_tags\n",
    "        \n",
    "    if not parsed:\n",
    "        tags = None\n",
    "            \n",
    "    return parsed, tags, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse nd tags which define nodes of a way\n",
    "def audit_way_nodes(way):\n",
    "    nodes = []\n",
    "    errs = []\n",
    "    position = 0\n",
    "    for node in way.iter('nd'):\n",
    "        parsed, errs_curr = audit_fields(node, way_nodes_fields)\n",
    "        \n",
    "        if parsed:\n",
    "            parsed['id'] = int(way.get('id'))\n",
    "            parsed['position'] = position\n",
    "            nodes.append(parsed)\n",
    "            position += 1\n",
    "            \n",
    "        else:\n",
    "            errs.append('Bad way node', node.attrib, errs_curr)\n",
    "    \n",
    "    return nodes, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse way, its tags and nodes\n",
    "def audit_way(way):\n",
    "    \n",
    "    parsed, errs = audit_fields(way, way_fields)\n",
    "            \n",
    "    if parsed:\n",
    "        nodes, errs_nodes = audit_way_nodes(way)\n",
    "        tags, errs_tags = audit_tags(way)\n",
    "        errs = errs_nodes + errs_tags\n",
    "    \n",
    "    if not parsed:\n",
    "        nodes = None\n",
    "        tags = None\n",
    "        \n",
    "    return parsed, nodes, tags, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorize_errs(errs):\n",
    "    errs_cat = defaultdict(list)\n",
    "    for err in errs:\n",
    "        try:\n",
    "            cat = err[2][0][0][0]\n",
    "            errs_cat[cat].append(err)\n",
    "        except:\n",
    "            errs_cat['other'].append(err)\n",
    "    return errs_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num errors: 1\n",
      "House id pattern not matching: 1\n"
     ]
    }
   ],
   "source": [
    "errs_glob = []\n",
    "def audit(osm_filename):\n",
    "    global errs_glob\n",
    "    \n",
    "    count = 0\n",
    "#    tag_count = defaultdict(int)\n",
    "#    streets = defaultdict(int)\n",
    "    errs = []\n",
    "    for elem in get_element(osm_filename, tags=('node', 'way')):\n",
    "        \n",
    "        count += 1  \n",
    "        \n",
    "        if elem.tag == \"node\":\n",
    "            node, tags, errs_curr = audit_node(elem)\n",
    "        elif elem.tag == \"way\":\n",
    "            way, way_nodes, tags, errs_curr = audit_way(elem)\n",
    "        \n",
    "            \n",
    "        if errs_curr:\n",
    "            errs.append(('bad elem', elem.attrib, errs_curr))\n",
    "#            pp.pprint(errs[-1])\n",
    "#        else:\n",
    "#            for tag in tags:\n",
    "#                tag_count[tag['type'] + \":\" + tag['key']] += 1\n",
    "                \n",
    "#                if tag['key'] == 'street' and len(tag['value'].split(' ')) > 1:\n",
    "#                    words = tag['value'].split(' ')\n",
    "#                    streets[words[0]] +=1\n",
    "#                    streets[words[-1]] +=1\n",
    "              \n",
    "                 \n",
    "#        if count > 1000:\n",
    "#            break\n",
    "    errs_glob = errs\n",
    "    print(\"Num errors: {}\".format(len(errs)))\n",
    "    errs_cat = categorize_errs(errs)\n",
    "    for cat in errs_cat:\n",
    "        print(\"{}: {}\".format(cat, len(errs_cat[cat])))\n",
    "#    for key in sorted(streets, key=streets.get, reverse=True):\n",
    "#        if streets[key] == 1:\n",
    "#            break\n",
    "#        print(key + \": \" + str(streets[key]))\n",
    "#    print(\"\")\n",
    "#    for key in sorted(tag_count, key=tag_count.get, reverse=True):\n",
    "#        print(key + \": \" + str(tag_count[key]))\n",
    "#        if tag_count[key] < 100:\n",
    "#            break\n",
    "\n",
    "audit(osm_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House id pattern not matching: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "errs_cat = categorize_errs(errs_glob)\n",
    "\n",
    "for cat, errs in errs_cat.items():\n",
    "    print(\"{}: {}\".format(cat, len(errs)))\n",
    "\n",
    "print(\"\")\n",
    "for err in errs_cat['First number is not consistent']:\n",
    "    pp.pprint(err[2][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and save as CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_schema = {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "SCHEMA = {\n",
    "    'nodes': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'nodes_tags': tags_schema,\n",
    "    'ways': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'ways_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'ways_tags': tags_schema,\n",
    "    'users' : {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'username': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_fields_csv_names = ['id', 'lat', 'lon', 'uid', 'version', 'changeset', 'timestamp']\n",
    "way_fields_csv_names = ['id', 'uid', 'version', 'changeset', 'timestamp']\n",
    "tag_fields_csv_names = ['id', 'key', 'value', 'type']\n",
    "way_nodes_fields_csv_names = ['id', 'node_id', 'position']\n",
    "user_fields_csv_names = ['id', 'username']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        pp.pprint(element)\n",
    "        raise Exception(message_string.format(field, error_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "    \n",
    "    def write(self, rowrows):\n",
    "        if type(rowrows) == type(list()):\n",
    "            self.writerows(rowrows)\n",
    "        elif type(rowrows) == type(dict()):\n",
    "            self.writerow(rowrows)\n",
    "        else:\n",
    "            raise Exception(\"Wrong type to write, list or dict expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(csv_filename_nodes, 'wb') as nodes_file, \\\n",
    "         codecs.open(csv_filename_nodes_tags, 'wb') as nodes_tags_file, \\\n",
    "         codecs.open(csv_filename_ways, 'wb') as ways_file, \\\n",
    "         codecs.open(csv_filename_ways_nodes, 'wb') as ways_nodes_file, \\\n",
    "         codecs.open(csv_filename_ways_tags, 'wb') as ways_tags_file, \\\n",
    "         codecs.open(csv_filename_users, 'wb') as users_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, node_fields_csv_names)\n",
    "        nodes_tags_writer = UnicodeDictWriter(nodes_tags_file, tag_fields_csv_names)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, way_fields_csv_names)\n",
    "        ways_nodes_writer = UnicodeDictWriter(ways_nodes_file, way_nodes_fields_csv_names)\n",
    "        ways_tags_writer = UnicodeDictWriter(ways_tags_file, tag_fields_csv_names)\n",
    "        users_writer = UnicodeDictWriter(users_file, user_fields_csv_names)\n",
    "        \n",
    "        writers = {'nodes': nodes_writer,\n",
    "                  'nodes_tags': nodes_tags_writer,\n",
    "                  'ways': ways_writer,\n",
    "                  'ways_nodes': ways_nodes_writer,\n",
    "                  'ways_tags': ways_tags_writer,\n",
    "                  'users': users_writer}\n",
    "        \n",
    "        # It seems that sqlite does not like headers\n",
    "        #for writer in writers.values():\n",
    "        #    writer.writeheader()\n",
    "            \n",
    "        validator = cerberus.Validator()\n",
    "        errs = []\n",
    "        user_ids = set()\n",
    "    \n",
    "        for elem in get_element(file_in, tags=('node', 'way')):\n",
    "            \n",
    "            parsed = {}\n",
    "            if elem.tag == \"node\":\n",
    "                node, tags, errs_curr = audit_node(elem)\n",
    "                if node:\n",
    "                    parsed['nodes'] = node\n",
    "                    parsed['nodes_tags'] = tags\n",
    "                        \n",
    "            elif elem.tag == \"way\":\n",
    "                way, way_nodes, tags, errs_curr = audit_way(elem)\n",
    "                if way:\n",
    "                    parsed['ways'] = way \n",
    "                    parsed['ways_nodes'] = way_nodes\n",
    "                    parsed['ways_tags'] = tags \n",
    "                    \n",
    "            if errs_curr:\n",
    "                errs.append(('bad elem', elem.attrib, errs_curr))\n",
    "                #pp.pprint(errs[-1])\n",
    "            \n",
    "            if parsed:\n",
    "                \n",
    "                # move username to the users table\n",
    "                uid = parsed[elem.tag + 's']['uid']\n",
    "                username = parsed[elem.tag + 's']['user']\n",
    "                del parsed[elem.tag + 's']['user']\n",
    "\n",
    "                if uid not in user_ids:\n",
    "                    user_ids.add(uid)\n",
    "                    parsed['users'] = {'id': uid,\n",
    "                                      'username': username}\n",
    "                \n",
    "                if validate is True:\n",
    "                    validate_element(parsed, validator)\n",
    "            \n",
    "                for table in parsed:\n",
    "                    writers[table].write(parsed[table])\n",
    "                    \n",
    "process_map(osm_filename, validate=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
